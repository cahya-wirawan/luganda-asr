{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Luganda ASR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOCCgJkN9nUNPAmz6QP83e+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cahya-wirawan/luganda-asr/blob/main/Luganda_ASR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic Speech Recognition  (ASR) for Luganda\n",
        "This is the Python Notebook to describe how to train ASR model for Luganda, evaluate it and create submission file for the [Mozilla Luganda Automatic Speech Recognition](https://zindi.africa/competitions/mozilla-luganda-automatic-speech-recognition/).\n",
        "\n",
        "We use several python scripts to do the training/fine-tuning, evaluation, submission file creation:\n",
        "- run_finetuning.py\n",
        "- run_evaluation.py\n",
        "- run_submission.py "
      ],
      "metadata": {
        "id": "U5NlZqLxJRnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the availability of the GPU"
      ],
      "metadata": {
        "id": "54VzOwvrMAIv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp-wU9KwNBoX",
        "outputId": "33c13ce1-0b1c-44e3-eca9-c797f3ca6608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 20 15:42:51 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            25G        605M         22G        1.2M        2.0G         24G\n",
            "Swap:            0B          0B          0B\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!free -h"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source Code Preparation"
      ],
      "metadata": {
        "id": "qXE7Fg4qhLFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the source code from https://github.com/cahya-wirawan/luganda-asr.git"
      ],
      "metadata": {
        "id": "b_bjt6ibhhdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf /content/luganda-asr\n",
        "!git clone https://github.com/cahya-wirawan/luganda-asr.git"
      ],
      "metadata": {
        "id": "jbsU1U4-vw9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43fbe04c-32b8-4da2-f6f7-c1d728086769"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'luganda-asr'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 100 (delta 51), reused 50 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (100/100), 6.37 MiB | 26.73 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/luganda-asr\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJU0j4xFH21S",
        "outputId": "fa9f683e-3e44-41d6-e622-f9fc8c8b42b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/luganda-asr\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the requirements"
      ],
      "metadata": {
        "id": "frnIcFhThxq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "f40I2tjtyS7f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "\n",
        "Since we can't provide the Mozilla Common Voice dataset directly here due to its License, we ask you to download it from https://commonvoice.mozilla.org/lg/datasets directly and the same with test dataset from Zindi which can be downloaded from https://zindi.africa/competitions/mozilla-luganda-automatic-speech-recognition/data\n",
        "\n",
        "Please save all of it in your Google Drive directory, which we will mount it in this notebook. The directory structure in Google Drive should look as following after the mounting:\n",
        "\n",
        "/content/drive/MyDrive/Luganda\n",
        "- cv-corpus-7.0-2021-07-21-lg.tar.gz\n",
        "- SampleSubmission.csv\n",
        "- test_audio.zip\n",
        "- Test.csv\n"
      ],
      "metadata": {
        "id": "MAA1DQPVeBmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARvOjdMne1LY",
        "outputId": "9c0aeeef-baea-4d63-b9c4-f5c34468c8e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "luganda_data_dir = \"/content/drive/MyDrive/Luganda\"\n",
        "luganda_cv_corpus = f\"{luganda_data_dir}/cv-corpus-7.0-2021-07-21-lg.tar.gz\"\n",
        "luganda_test_audio_file = f\"{luganda_data_dir}/test_audio.zip\"\n",
        "luganda_test_file = f\"{luganda_data_dir}/Test.csv\"\n",
        "\n",
        "!ls -l $luganda_data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlhD5Y1E9lVx",
        "outputId": "2b4164f0-ad6a-44d1-95c3-3228154d5cc9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1914072\n",
            "-rw------- 1 root root 1722860000 Jan 18 18:05 cv-corpus-7.0-2021-07-21-lg.tar.gz\n",
            "-rw------- 1 root root      91886 Jan 18 16:41 SampleSubmission.csv\n",
            "-rw------- 1 root root  236764554 Jan 18 16:39 test_audio.zip\n",
            "-rw------- 1 root root     292195 Jan 18 16:29 Test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# Uncompressing the test_audio.zip and cv-corpus-7.0-2021-07-21-lg.tar.gz to the \n",
        "# directory /content/data.\n",
        "# It takes around 40s\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "## clean up the directory /content/data/\n",
        "!rm -rf /content/data\n",
        "\n",
        "!mkdir -p /content/data/zindi\n",
        "%cd /content/data/zindi\n",
        "!unzip -o $luganda_test_audio_file && cp $luganda_test_file .\n",
        "%cd /content/data\n",
        "!tar xvzf $luganda_cv_corpus "
      ],
      "metadata": {
        "id": "cJ0loUci9csm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"Content of /content/data:\" && ls -l /content/data\n",
        "!echo\n",
        "!echo \"Content of /content/data/zindi:\" && ls -l /content/data/zindi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD9NdTcNJqEF",
        "outputId": "b382e0e6-f87a-4767-af2f-aa96d6880117"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content of /content/data:\n",
            "total 8\n",
            "drwxr-xr-x 3 root root 4096 Jan 20 15:44 cv-corpus-7.0-2021-07-21\n",
            "drwxr-xr-x 4 root root 4096 Jan 20 15:44 zindi\n",
            "\n",
            "Content of /content/data/zindi:\n",
            "total 556\n",
            "drwxr-xr-x 3 root root   4096 Jan 20 15:44 __MACOSX\n",
            "drwxr-xr-x 2 root root 266240 Oct 22 06:14 test_audio\n",
            "-rw------- 1 root root 292195 Jan 20 15:44 Test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training\n",
        "\n",
        "We have fine-tuned the Facebook Wav2Vec2 model with the Luganda Common Voice dataset and stored it in https://huggingface.co/indonesian-nlp/wav2vec2-luganda. The model has been trained for 200 epochs in 4 hours and 30 minutes using 8 GPUs.\n",
        "\n",
        "We use the script run_finetuning.py to train the model. \n",
        "Due to resource and time limitation in Google Colab,\n",
        "we skip the model training here, but we run the evaluation and creation of the submission file. However, feel free to run following command for testing purpose:\n",
        "\n",
        "```!python run_finetuning.py finetuning_common_voice_1epoch.json```\n",
        "\n",
        "It will run the training for only one epoch which will take around 2 hours and 40 minutes in Google Colab.\n",
        "\n",
        "### Usage\n",
        "For training using single GPU\n",
        "``` \n",
        "% python run_finetuning.py <argument json file>\n",
        "``` \n",
        "For training using multi GPUs, for example 8 GPUs.\n",
        "``` \n",
        "% python -m torch.distributed.launch --nproc_per_node=8 run_finetuning.py <argument json file>\n",
        "``` \n",
        "Our model \"indonesian-nlp/wav2vec2-luganda\" has been trained using following command:\n",
        "``` \n",
        "% python -m torch.distributed.launch --nproc_per_node=8 run_finetuning.py finetuning_common_voice.json\n",
        "```\n",
        "\n",
        "List of possible arguments:\n",
        "``` \n",
        "% python run_finetuning.py -h\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "eYMN6cXWwN8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# We disable here the training to save times, but feel free to run it by \n",
        "# uncommenting the command \"!python run_finetuning.py finetuning_common_voice_1epoch.json\"\n",
        "%cd /content/luganda-asr\n",
        "\n",
        "!mkdir -p output\n",
        "#!python run_finetuning.py finetuning_common_voice_1epoch.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZI7R-qJwnIx",
        "outputId": "c2292007-44d6-4caa-f41c-c0973d649df6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/luganda-asr\n",
            "CPU times: user 3.52 ms, sys: 10.4 ms, total: 13.9 ms\n",
            "Wall time: 111 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams Language Model\n",
        "\n",
        "We use the n-grams language model [KenLM](https://github.com/kpu/kenlm) to reduce further the Word Error Rate (WER)."
      ],
      "metadata": {
        "id": "21AVc8H2LcbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we install the necessary linux packages to build the KenLM library"
      ],
      "metadata": {
        "id": "BR-zyW5rgtwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install build-essential libboost-all-dev cmake zlib1g-dev libbz2-dev liblzma-dev\n",
        "!sudo apt-get install libboost-all-dev libeigen3-dev"
      ],
      "metadata": {
        "id": "UNiCEM2FLgTb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we clone KenLM source and build it. The executables will be built in the directory \"kenlm/build/bin\""
      ],
      "metadata": {
        "id": "Hspfv7dkg6kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "%cd /content/\n",
        "!if [ ! -d kenlm ]; then git clone https://github.com/kpu/kenlm; fi\n",
        "!cd kenlm && mkdir build && cd build && cmake .. && make -j 4"
      ],
      "metadata": {
        "id": "MW9vByc2LrlS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can prepare the text from the CV corpus and build the KenLM binary \"5gram.bin\""
      ],
      "metadata": {
        "id": "HR42WzkhhoE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/luganda-asr/\n",
        "\n",
        "!python run_lm_preparation.py -n dataset/common_voice -c lg -d /content/data/cv-corpus-7.0-2021-07-21 -o 5gram.txt\n",
        "!../kenlm/build/bin/lmplz -o 5 < \"5gram.txt\" > \"5gram.arpa\"\n",
        "!../kenlm/build/bin/build_binary \"5gram.arpa\" \"5gram.bin\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHHiM722MAkL",
        "outputId": "9665be5a-0118-4d42-85bf-39250fc79f77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/luganda-asr\n",
            "Using custom data configuration lg-b5dd5bec651497f8\n",
            "Downloading and preparing dataset common_voice/lg to /root/.cache/huggingface/datasets/common_voice/lg-b5dd5bec651497f8/7.0.0/d2815414a38db497e900b5788f75958a15449c23acb8371ded02d3ed746d6206...\n",
            "Dataset common_voice downloaded and prepared to /root/.cache/huggingface/datasets/common_voice/lg-b5dd5bec651497f8/7.0.0/d2815414a38db497e900b5788f75958a15449c23acb8371ded02d3ed746d6206. Subsequent calls will reuse this data.\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/luganda-asr/5gram.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "tcmalloc: large alloc 3854925824 bytes == 0x5577b7172000 @  0x7f0b888441e7 0x5577b58227e2 0x5577b57bd4fe 0x5577b579c2eb 0x5577b5788066 0x7f0b869ddbf7 0x5577b5789baa\n",
            "tcmalloc: large alloc 17989623808 bytes == 0x55789cdca000 @  0x7f0b888441e7 0x5577b58227e2 0x5577b581180a 0x5577b5812248 0x5577b579c308 0x5577b5788066 0x7f0b869ddbf7 0x5577b5789baa\n",
            "****************************************************************************************************\n",
            "Unigram tokens 315562 types 29210\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:350520 2:2133595776 3:4000492288 4:6400786944 5:9334481920\n",
            "tcmalloc: large alloc 9334489088 bytes == 0x5577b7172000 @  0x7f0b888441e7 0x5577b58227e2 0x5577b581180a 0x5577b5812248 0x5577b579c8d7 0x5577b5788066 0x7f0b869ddbf7 0x5577b5789baa\n",
            "tcmalloc: large alloc 2133598208 bytes == 0x5579e37e0000 @  0x7f0b888441e7 0x5577b58227e2 0x5577b581180a 0x5577b5812248 0x5577b579ccdd 0x5577b5788066 0x7f0b869ddbf7 0x5577b5789baa\n",
            "tcmalloc: large alloc 4000497664 bytes == 0x557a62aa2000 @  0x7f0b888441e7 0x5577b58227e2 0x5577b581180a 0x5577b5812248 0x5577b579ccdd 0x5577b5788066 0x7f0b869ddbf7 0x5577b5789baa\n",
            "tcmalloc: large alloc 6400794624 bytes == 0x557cce2b4000 @  0x7f0b888441e7 0x5577b58227e2 0x5577b581180a 0x5577b5812248 0x5577b579ccdd 0x5577b5788066 0x7f0b869ddbf7 0x5577b5789baa\n",
            "Statistics:\n",
            "1 29210 D1=0.715755 D2=1.11374 D3+=1.35288\n",
            "2 104286 D1=0.845218 D2=1.05038 D3+=1.44071\n",
            "3 135471 D1=0.876935 D2=0.595336 D3+=1.96891\n",
            "4 129896 D1=0.876117 D2=0.288674 D3+=2.21755\n",
            "5 111682 D1=0.328236 D2=1.26613 D3+=2.73006\n",
            "Memory estimate for binary LM:\n",
            "type       kB\n",
            "probing 11368 assuming -p 1.5\n",
            "probing 13648 assuming -r models -p 1.5\n",
            "trie     5611 without quantization\n",
            "trie     3183 assuming -q 8 -b 8 quantization \n",
            "trie     5145 assuming -a 22 array pointer compression\n",
            "trie     2718 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:350520 2:1668576 3:2709420 4:3117504 5:3127096\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:350520 2:1668576 3:2709420 4:3117504 5:3127096\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:28049896 kB\tVmRSS:3823112 kB\tRSSMax:3823268 kB\tuser:0.689387\tsys:1.81802\tCPU:2.50745\treal:2.35143\n",
            "Reading 5gram.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "To test our fine-tuned model, we evaluate it with test split of Mozilla Common Voice dataset version 6.1 and 7.0. The evaluation also uses the Ken Language Model (KenLM) 5gram.bin we created from the text of Common Voice 7.0.\n",
        "\n",
        "\n",
        "### Usage\n",
        "Following is the command to evaluate test split of Mozilla Common Voice dataset using our model \"indonesian-nlp/wav2vec2-luganda\" and using the KenLM:\n",
        "``` \n",
        "% python run_evaluation.py -m indonesian-nlp/wav2vec2-luganda -n common_voice -c lg -k 5gram.bin --test_pct 100\n",
        "```\n",
        "List of possible arguments:\n",
        "``` \n",
        "% python run_evaluation.py -h\n",
        "usage: run_evaluation.py [-h] -m MODEL_NAME -n NAME -c CONFIG_NAME [-d DATA_DIR] [-b BATCH_SIZE] [-k KENLM] [--num_workers NUM_WORKERS] [-w BEAM_WIDTH] [--test_pct TEST_PCT] [--cpu]\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help            show this help message and exit\n",
        "  -m MODEL_NAME, --model_name MODEL_NAME\n",
        "                        The wav2vec2 model name\n",
        "  -n NAME, --name NAME  The name of dataset\n",
        "  -c CONFIG_NAME, --config_name CONFIG_NAME\n",
        "                        The config name of the dataset\n",
        "  -d DATA_DIR, --data_dir DATA_DIR\n",
        "                        The directory contains the dataset\n",
        "  -b BATCH_SIZE, --batch_size BATCH_SIZE\n",
        "                        Batch size\n",
        "  -k KENLM, --kenlm KENLM\n",
        "                        Path to KenLM model\n",
        "  --num_workers NUM_WORKERS\n",
        "                        KenLM's number of workers\n",
        "  -w BEAM_WIDTH, --beam_width BEAM_WIDTH\n",
        "                        KenLM's beam width\n",
        "  --test_pct TEST_PCT   Percentage of the test set\n",
        "  --cpu                 Force to use CPU\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "zkbnzaStUCT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on Common Voice version 6.1\n",
        "\n",
        "We evaluate the ASR model \"indonesian-nlp/wav2vec2-luganda\" on the test split of Common Voice Dataset for Luganda (version 6.1). It takes around 6 minutes. We get here the Word Error Rate (WER) of **7.37%**."
      ],
      "metadata": {
        "id": "Yrwb5AURVGcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "%cd /content/luganda-asr\n",
        "!python run_evaluation.py -m indonesian-nlp/wav2vec2-luganda -n common_voice -c lg -k 5gram.bin --test_pct 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFsYf3VB5nyz",
        "outputId": "02e6ea57-5bcb-419a-bd3e-1ec2e1c3e32a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/luganda-asr\n",
            "Downloading: 100% 214/214 [00:00<00:00, 360kB/s]\n",
            "Downloading: 100% 181/181 [00:00<00:00, 260kB/s]\n",
            "Downloading: 100% 259/259 [00:00<00:00, 350kB/s]\n",
            "Downloading: 100% 85.0/85.0 [00:00<00:00, 99.7kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading: 100% 1.89k/1.89k [00:00<00:00, 2.32MB/s]\n",
            "Downloading: 100% 1.18G/1.18G [00:52<00:00, 24.0MB/s]\n",
            "Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
            "No known unigrams provided, decoding results might be a lot worse.\n",
            "Downloading: 23.3kB [00:00, 20.3MB/s]       \n",
            "Downloading: 168kB [00:00, 82.3MB/s]        \n",
            "Downloading and preparing dataset common_voice/lg (download: 198.55 MiB, generated: 205.82 MiB, post-processed: Unknown size, total: 404.38 MiB) to /root/.cache/huggingface/datasets/common_voice/lg/6.1.0/5693bfc0feeade582a78c2fb250bc88f52bd86f0a7f1bb22bfee67e715de30fd...\n",
            "Downloading: 100% 208M/208M [00:07<00:00, 26.3MB/s]\n",
            "Dataset common_voice downloaded and prepared to /root/.cache/huggingface/datasets/common_voice/lg/6.1.0/5693bfc0feeade582a78c2fb250bc88f52bd86f0a7f1bb22bfee67e715de30fd. Subsequent calls will reuse this data.\n",
            "100% 584/584 [00:08<00:00, 71.84ex/s]\n",
            "100% 584/584 [01:31<00:00,  6.41ex/s]\n",
            "Downloading: 4.49kB [00:00, 3.82MB/s]       \n",
            "tcmalloc: large alloc 1253105664 bytes == 0x55659ed14000 @  0x7f51a6816615 0x556478c514cc 0x556478d3147a 0x556478c542ed 0x556478c54240 0x556478cc7973 0x556478c55afa 0x556478cc7d00 0x556478c55afa 0x556478cc3915 0x556478cc29ee 0x556478c55bda 0x556478cc3915 0x556478c55afa 0x556478cc3915 0x556478cc29ee 0x556478c55bda 0x556478cc3915 0x556478cc29ee 0x556478c5648c 0x556478c56698 0x556478cc4fe4 0x556478cc29ee 0x556478c55bda 0x556478cc3915 0x556478c55afa 0x556478cc3915 0x556478cc29ee 0x556478c55bda 0x556478cc3915 0x556478cc29ee\n",
            "tcmalloc: large alloc 1566384128 bytes == 0x5565e9822000 @  0x7f51a6816615 0x556478c514cc 0x556478d3147a 0x556478c542ed 0x556478c54240 0x556478cc7973 0x556478c55afa 0x556478cc7d00 0x556478c55afa 0x556478cc3915 0x556478cc29ee 0x556478c55bda 0x556478cc3915 0x556478c55afa 0x556478cc3915 0x556478cc29ee 0x556478c55bda 0x556478cc3915 0x556478cc29ee 0x556478c5648c 0x556478c56698 0x556478cc4fe4 0x556478cc29ee 0x556478c55bda 0x556478cc3915 0x556478c55afa 0x556478cc3915 0x556478cc29ee 0x556478c55bda 0x556478cc3915 0x556478cc29ee\n",
            "  0% 0/37 [00:00<?, ?ba/s]/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1093: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  return (input_length - kernel_size) // stride + 1\n",
            "100% 37/37 [02:58<00:00,  4.82s/ba]\n",
            "WER: 7.37%\n",
            "CPU times: user 3.85 s, sys: 920 ms, total: 4.77 s\n",
            "Wall time: 6min 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on Common Voice version 7.0\n",
        "\n",
        "We evaluate the ASR model \"indonesian-nlp/wav2vec2-luganda\" on the test split of Common Voice Dataset for Luganda (version 7.0). It takes around 25 minutes. We get here the Word Error Rate (WER) of **7.53%**."
      ],
      "metadata": {
        "id": "J_zPIeviVr-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "%cd /content/luganda-asr\n",
        "!python run_evaluation.py -m indonesian-nlp/wav2vec2-luganda -n ./dataset/common_voice -c lg --data_dir /content/data/cv-corpus-7.0-2021-07-21 -k 5gram.bin --test_pct 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdXpjLbJRruk",
        "outputId": "cf92283e-fde7-4f0f-8cbd-7f27da896c96"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/luganda-asr\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
            "No known unigrams provided, decoding results might be a lot worse.\n",
            "Using custom data configuration lg-b5dd5bec651497f8\n",
            "Reusing dataset common_voice (/root/.cache/huggingface/datasets/common_voice/lg-b5dd5bec651497f8/7.0.0/d2815414a38db497e900b5788f75958a15449c23acb8371ded02d3ed746d6206)\n",
            "100% 4276/4276 [00:46<00:00, 92.86ex/s] \n",
            "100% 4276/4276 [02:08<00:00, 33.39ex/s]\n",
            "tcmalloc: large alloc 1253105664 bytes == 0x5606d3e50000 @  0x7f785f841615 0x5605422fc4cc 0x5605423dc47a 0x5605422ff2ed 0x5605422ff240 0x560542372973 0x560542300afa 0x560542372d00 0x560542300afa 0x56054236e915 0x56054236d9ee 0x560542300bda 0x56054236e915 0x560542300afa 0x56054236e915 0x56054236d9ee 0x560542300bda 0x56054236e915 0x56054236d9ee 0x56054230148c 0x560542301698 0x56054236ffe4 0x56054236d9ee 0x560542300bda 0x56054236e915 0x560542300afa 0x56054236e915 0x56054236d9ee 0x560542300bda 0x56054236e915 0x56054236d9ee\n",
            "tcmalloc: large alloc 1566384128 bytes == 0x56066456a000 @  0x7f785f841615 0x5605422fc4cc 0x5605423dc47a 0x5605422ff2ed 0x5605422ff240 0x560542372973 0x560542300afa 0x560542372d00 0x560542300afa 0x56054236e915 0x56054236d9ee 0x560542300bda 0x56054236e915 0x560542300afa 0x56054236e915 0x56054236d9ee 0x560542300bda 0x56054236e915 0x56054236d9ee 0x56054230148c 0x560542301698 0x56054236ffe4 0x56054236d9ee 0x560542300bda 0x56054236e915 0x560542300afa 0x56054236e915 0x56054236d9ee 0x560542300bda 0x56054236e915 0x56054236d9ee\n",
            "  0% 0/268 [00:00<?, ?ba/s]/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1093: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  return (input_length - kernel_size) // stride + 1\n",
            "100% 268/268 [10:44<00:00,  2.40s/ba]\n",
            "WER: 7.53%\n",
            "CPU times: user 7.12 s, sys: 1.46 s, total: 8.58 s\n",
            "Wall time: 13min 59s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission\n",
        "\n",
        "We will create the submission file \"submissions/luganda-asr.csv\"\n",
        "using the ASR model \"indonesian-nlp/wav2vec2-luganda\" on the test set\n",
        "provided by Zindi.\n",
        "It takes around 40 minutes\n",
        "\n",
        "### Usage\n",
        "```\n",
        "$ python run_submission.py -h\n",
        "usage: run_submission.py [-h] -m MODEL_NAME -d DATA_DIR -o OUTPUT_FILE [-b BATCH_SIZE] [-k KENLM] [-n NUM_WORKERS] [-w BEAM_WIDTH] [--test_pct TEST_PCT]\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help            show this help message and exit\n",
        "  -m MODEL_NAME, --model_name MODEL_NAME\n",
        "                        The wav2vec2 model name\n",
        "  -d DATA_DIR, --data_dir DATA_DIR\n",
        "                        The directory contains the Zindi dataset (Train.csv, Test.csv and validated_dataset)\n",
        "  -o OUTPUT_FILE, --output_file OUTPUT_FILE\n",
        "                        The file name of the prediction result\n",
        "  -b BATCH_SIZE, --batch_size BATCH_SIZE\n",
        "                        Batch size\n",
        "  -k KENLM, --kenlm KENLM\n",
        "                        Path to KenLM model\n",
        "  -n NUM_WORKERS, --num_workers NUM_WORKERS\n",
        "                        KenLM's number of workers\n",
        "  -w BEAM_WIDTH, --beam_width BEAM_WIDTH\n",
        "                        KenLM's beam width\n",
        "  --test_pct TEST_PCT   Percentage of the test set\n",
        "```"
      ],
      "metadata": {
        "id": "-X1KGoJrWEiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "%cd /content/luganda-asr\n",
        "!mkdir -p submissions\n",
        "# For testing purpose, we can create submission file for only 1% of test dataset\n",
        "# which takes around 44s.\n",
        "#!python run_submission.py -o submissions/luganda-asr.csv -m indonesian-nlp/wav2vec2-luganda --data_dir /content/data/zindi -k 5gram.bin --test_pct 1\n",
        "\n",
        "# Following command creates submission file for 100% of test dataset which takes\n",
        "# around 40 minutes.\n",
        "!python run_submission.py -o submissions/luganda-asr.csv -m indonesian-nlp/wav2vec2-luganda --data_dir /content/data/zindi -k 5gram.bin\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xtbb0l2G6Q4k",
        "outputId": "0a6ab9c8-a460-44b2-f1d9-ef8b5517dcb8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/luganda-asr\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
            "No known unigrams provided, decoding results might be a lot worse.\n",
            "Using custom data configuration lg-e6ac6d8c877e86bb\n",
            "Downloading and preparing dataset zindi/lg to /root/.cache/huggingface/datasets/zindi/lg-e6ac6d8c877e86bb/1.0.0/48535cc6e254ea4fe8bd529ebd18452c88df0776030e5c69a33ea03b6bcf7436...\n",
            "manual_dir: /content/data/zindi\n",
            "datadir: /content/data/zindi\n",
            "Dataset zindi downloaded and prepared to /root/.cache/huggingface/datasets/zindi/lg-e6ac6d8c877e86bb/1.0.0/48535cc6e254ea4fe8bd529ebd18452c88df0776030e5c69a33ea03b6bcf7436. Subsequent calls will reuse this data.\n",
            "100% 7067/7067 [01:15<00:00, 93.08ex/s]\n",
            "  0% 0/442 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1093: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  return (input_length - kernel_size) // stride + 1\n",
            "100% 442/442 [16:00<00:00,  2.17s/it]\n",
            "\n",
            "The prediction result has been saved to submissions/luganda-asr.csv\n",
            "CPU times: user 8.03 s, sys: 1.45 s, total: 9.48 s\n",
            "Wall time: 17min 32s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rugKCFthWlCl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}