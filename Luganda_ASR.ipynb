{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Luganda ASR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO+5m1xiT3go2fI0RcnF4NF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cahya-wirawan/luganda-asr/blob/main/Luganda_ASR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp-wU9KwNBoX",
        "outputId": "0a149990-ff6d-4f6f-f3ff-1d7b1d9b40c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 19 05:08:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            25G        606M         22G        1.2M        2.0G         24G\n",
            "Swap:            0B          0B          0B\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!free -h"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation of the Luganda ASR  source code "
      ],
      "metadata": {
        "id": "qXE7Fg4qhLFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the source code from https://github.com/cahya-wirawan/luganda-asr.git"
      ],
      "metadata": {
        "id": "b_bjt6ibhhdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cahya-wirawan/luganda-asr.git"
      ],
      "metadata": {
        "id": "jbsU1U4-vw9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723bd39c-08cc-47b9-c8b0-00b020092388"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'luganda-asr'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 61 (delta 24), reused 39 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/luganda-asr\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJU0j4xFH21S",
        "outputId": "58f6a3f6-026c-4dee-cd64-7ba5947f3dcf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/luganda-asr\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the requirements"
      ],
      "metadata": {
        "id": "frnIcFhThxq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "f40I2tjtyS7f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "\n",
        "We prepare the training and test data from Google Drive directory with following file structure:\n",
        "\n",
        "/content/drive/MyDrive/Luganda\n",
        "- cv-corpus-7.0-2021-07-21-lg.tar.gz\n",
        "- SampleSubmission.csv\n",
        "- test_audio.zip\n",
        "- Test.csv\n"
      ],
      "metadata": {
        "id": "MAA1DQPVeBmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARvOjdMne1LY",
        "outputId": "a6e88f8e-86b6-4349-d5ce-b336a45070e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "luganda_data_dir = \"/content/drive/MyDrive/Luganda\"\n",
        "luganda_cv_corpus = f\"{luganda_data_dir}/cv-corpus-7.0-2021-07-21-lg.tar.gz\"\n",
        "luganda_test_audio_file = f\"{luganda_data_dir}/test_audio.zip\"\n",
        "luganda_test_file = f\"{luganda_data_dir}/Test.csv\"\n",
        "\n",
        "!ls -l $luganda_data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlhD5Y1E9lVx",
        "outputId": "18208213-07e1-4951-8cc5-875f82d82868"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1914072\n",
            "-rw------- 1 root root 1722860000 Jan 18 18:05 cv-corpus-7.0-2021-07-21-lg.tar.gz\n",
            "-rw------- 1 root root      91886 Jan 18 16:41 SampleSubmission.csv\n",
            "-rw------- 1 root root  236764554 Jan 18 16:39 test_audio.zip\n",
            "-rw------- 1 root root     292195 Jan 18 16:29 Test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%capture\n",
        "\n",
        "# Uncompressing the test_audio.zip and cv-corpus-7.0-2021-07-21-lg.tar.gz to the \n",
        "# directory /content/data.\n",
        "# It takes around 40s\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "## clean up the directory /content/data/\n",
        "!rm -rf /content/data\n",
        "\n",
        "!mkdir -p /content/data/zindi\n",
        "%cd /content/data/zindi\n",
        "!unzip -o $luganda_test_audio_file && cp $luganda_test_file .\n",
        "%cd /content/data\n",
        "!tar xvzf $luganda_cv_corpus "
      ],
      "metadata": {
        "id": "cJ0loUci9csm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"Content of /content/data:\" && ls -l /content/data\n",
        "!echo\n",
        "!echo \"Content of /content/data/zindi:\" && ls -l /content/data/zindi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD9NdTcNJqEF",
        "outputId": "b14ce194-8999-4f03-afd0-d0ac6d759b26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content of /content/data:\n",
            "total 8\n",
            "drwxr-xr-x 3 root root 4096 Jan 19 05:12 cv-corpus-7.0-2021-07-21\n",
            "drwxr-xr-x 4 root root 4096 Jan 19 05:12 zindi\n",
            "\n",
            "Content of /content/data/zindi:\n",
            "total 556\n",
            "drwxr-xr-x 3 root root   4096 Jan 19 05:11 __MACOSX\n",
            "drwxr-xr-x 2 root root 266240 Oct 22 06:14 test_audio\n",
            "-rw------- 1 root root 292195 Jan 19 05:12 Test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training\n",
        "\n",
        "We will fine-tune the Facebook Wav2Vec2 model with the Luganda Common Voice dataset."
      ],
      "metadata": {
        "id": "eYMN6cXWwN8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "%cd /content/luganda-asr\n",
        "\n",
        "!mkdir -p output\n",
        "!python run_finetuning.py finetuning_common_voice_1epoch.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZI7R-qJwnIx",
        "outputId": "c3d303e7-5670-4d34-e54e-bf2d0a502760"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/luganda-asr\n",
            "01/19/2022 05:19:05 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "01/19/2022 05:19:05 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=8,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=2000,\n",
            "evaluation_strategy=IntervalStrategy.STEPS,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=2,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=True,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output/wav2vec2-common_voice-lg/runs/Jan19_05-19-05_0b351fef6201,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=2000,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1,\n",
            "output_dir=output/wav2vec2-common_voice-lg,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output/wav2vec2-common_voice-lg,\n",
            "save_on_each_node=False,\n",
            "save_steps=2000,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=1,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=300,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "01/19/2022 05:19:05 - WARNING - datasets.builder - Using custom data configuration lg-b5dd5bec651497f8\n",
            "Downloading and preparing dataset common_voice/lg to /root/.cache/huggingface/datasets/common_voice/lg-b5dd5bec651497f8/7.0.0/d2815414a38db497e900b5788f75958a15449c23acb8371ded02d3ed746d6206...\n",
            "Dataset common_voice downloaded and prepared to /root/.cache/huggingface/datasets/common_voice/lg-b5dd5bec651497f8/7.0.0/d2815414a38db497e900b5788f75958a15449c23acb8371ded02d3ed746d6206. Subsequent calls will reuse this data.\n",
            "01/19/2022 05:19:11 - WARNING - datasets.builder - Using custom data configuration lg-b5dd5bec651497f8\n",
            "01/19/2022 05:19:11 - WARNING - datasets.builder - Reusing dataset common_voice (/root/.cache/huggingface/datasets/common_voice/lg-b5dd5bec651497f8/7.0.0/d2815414a38db497e900b5788f75958a15449c23acb8371ded02d3ed746d6206)\n",
            "100% 42/42 [00:01<00:00, 26.35ba/s]\n",
            "100% 5/5 [00:00<00:00, 30.98ba/s]\n",
            "100% 41709/41709 [00:07<00:00, 5498.14ex/s]\n",
            "100% 4263/4263 [00:00<00:00, 5518.07ex/s]\n",
            "100% 1/1 [00:00<00:00,  2.94ba/s]\n",
            "100% 1/1 [00:00<00:00,  2.99ba/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"run_finetuning.py\", line 553, in <module>\n",
            "    main()\n",
            "  File \"run_finetuning.py\", line 420, in main\n",
            "    vocab_size=len(processor.tokenizer),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\", line 1276, in from_pretrained\n",
            "    **kwargs,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\", line 503, in from_pretrained\n",
            "    config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\", line 556, in get_config_dict\n",
            "    local_files_only=local_files_only,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\", line 844, in get_configuration_file\n",
            "    path_or_repo, revision=revision, use_auth_token=use_auth_token, local_files_only=local_files_only\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\", line 2103, in get_list_of_files\n",
            "    return list_repo_files(path_or_repo, revision=revision, token=token)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/huggingface_hub/hf_api.py\", line 885, in list_repo_files\n",
            "    repo_id, revision=revision, token=token, timeout=timeout\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/huggingface_hub/hf_api.py\", line 868, in model_info\n",
            "    r.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/models.py\", line 941, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 504 Server Error: Gateway Time-out for url: https://huggingface.co/api/models/facebook/wav2vec2-large-xlsr-53\n",
            "CPU times: user 635 ms, sys: 162 ms, total: 797 ms\n",
            "Wall time: 1min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "zkbnzaStUCT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on Common Voice version 6.1\n",
        "\n",
        "We evaluate the ASR model \"indonesian-nlp/wav2vec2-luganda\" on the test split of Common Voice Dataset for Luganda (version 6.1). The evaluation also uses the Ken Language Model (KenLM) 5gram.bin. It takes around 9 minutes. We get here the Word Error Rate (WER) of **7.37%**."
      ],
      "metadata": {
        "id": "Yrwb5AURVGcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "!python run_evaluation.py -m indonesian-nlp/wav2vec2-luganda -n common_voice -c lg -k 5gram.bin --test_pct 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFsYf3VB5nyz",
        "outputId": "939adf1e-d46b-4262-ad10-e1d11c06f2c6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading: 100% 1.18G/1.18G [00:32<00:00, 38.5MB/s]\n",
            "Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
            "No known unigrams provided, decoding results might be a lot worse.\n",
            "Reusing dataset common_voice (/root/.cache/huggingface/datasets/common_voice/lg/6.1.0/5693bfc0feeade582a78c2fb250bc88f52bd86f0a7f1bb22bfee67e715de30fd)\n",
            "100% 584/584 [00:08<00:00, 70.98ex/s]\n",
            "100% 584/584 [01:31<00:00,  6.37ex/s]\n",
            "Downloading: 4.49kB [00:00, 773kB/s]        \n",
            "tcmalloc: large alloc 1253105664 bytes == 0x55aea7cd0000 @  0x7f944d519615 0x55ad576814cc 0x55ad5776147a 0x55ad576842ed 0x55ad57684240 0x55ad576f7973 0x55ad57685afa 0x55ad576f7d00 0x55ad57685afa 0x55ad576f3915 0x55ad576f29ee 0x55ad57685bda 0x55ad576f3915 0x55ad57685afa 0x55ad576f3915 0x55ad576f29ee 0x55ad57685bda 0x55ad576f3915 0x55ad576f29ee 0x55ad5768648c 0x55ad57686698 0x55ad576f4fe4 0x55ad576f29ee 0x55ad57685bda 0x55ad576f3915 0x55ad57685afa 0x55ad576f3915 0x55ad576f29ee 0x55ad57685bda 0x55ad576f3915 0x55ad576f29ee\n",
            "tcmalloc: large alloc 1566384128 bytes == 0x55aef27de000 @  0x7f944d519615 0x55ad576814cc 0x55ad5776147a 0x55ad576842ed 0x55ad57684240 0x55ad576f7973 0x55ad57685afa 0x55ad576f7d00 0x55ad57685afa 0x55ad576f3915 0x55ad576f29ee 0x55ad57685bda 0x55ad576f3915 0x55ad57685afa 0x55ad576f3915 0x55ad576f29ee 0x55ad57685bda 0x55ad576f3915 0x55ad576f29ee 0x55ad5768648c 0x55ad57686698 0x55ad576f4fe4 0x55ad576f29ee 0x55ad57685bda 0x55ad576f3915 0x55ad57685afa 0x55ad576f3915 0x55ad576f29ee 0x55ad57685bda 0x55ad576f3915 0x55ad576f29ee\n",
            "  0% 0/37 [00:00<?, ?ba/s]/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1093: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  return (input_length - kernel_size) // stride + 1\n",
            "100% 37/37 [05:13<00:00,  8.49s/ba]\n",
            "WER: 7.37%\n",
            "CPU times: user 4.54 s, sys: 667 ms, total: 5.21 s\n",
            "Wall time: 8min 20s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on Common Voice version 7.0\n",
        "\n",
        "We evaluate the ASR model \"indonesian-nlp/wav2vec2-luganda\" on the test split of Common Voice Dataset for Luganda (version 7.0). The evaluation also uses the Ken Language Model (KenLM) 5gram.bin. It takes around 25 minutes. We get here the Word Error Rate (WER) of **7.53%**."
      ],
      "metadata": {
        "id": "J_zPIeviVr-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "!python run_evaluation.py -m indonesian-nlp/wav2vec2-luganda -n ./dataset/common_voice -c lg --data_dir /content/data/cv-corpus-7.0-2021-07-21 -k 5gram.bin --test_pct 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdXpjLbJRruk",
        "outputId": "91ac3236-4d77-49d9-d329-1e1b56b6400b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
            "No known unigrams provided, decoding results might be a lot worse.\n",
            "Using custom data configuration lg-b5dd5bec651497f8\n",
            "Reusing dataset common_voice (/root/.cache/huggingface/datasets/common_voice/lg-b5dd5bec651497f8/7.0.0/d2815414a38db497e900b5788f75958a15449c23acb8371ded02d3ed746d6206)\n",
            "100% 4276/4276 [00:48<00:00, 88.69ex/s] \n",
            "100% 4276/4276 [02:15<00:00, 31.65ex/s]\n",
            "tcmalloc: large alloc 1253105664 bytes == 0x5590e86d8000 @  0x7f08bad88615 0x558fbd8524cc 0x558fbd93247a 0x558fbd8552ed 0x558fbd855240 0x558fbd8c8973 0x558fbd856afa 0x558fbd8c8d00 0x558fbd856afa 0x558fbd8c4915 0x558fbd8c39ee 0x558fbd856bda 0x558fbd8c4915 0x558fbd856afa 0x558fbd8c4915 0x558fbd8c39ee 0x558fbd856bda 0x558fbd8c4915 0x558fbd8c39ee 0x558fbd85748c 0x558fbd857698 0x558fbd8c5fe4 0x558fbd8c39ee 0x558fbd856bda 0x558fbd8c4915 0x558fbd856afa 0x558fbd8c4915 0x558fbd8c39ee 0x558fbd856bda 0x558fbd8c4915 0x558fbd8c39ee\n",
            "tcmalloc: large alloc 1566384128 bytes == 0x5591331e6000 @  0x7f08bad88615 0x558fbd8524cc 0x558fbd93247a 0x558fbd8552ed 0x558fbd855240 0x558fbd8c8973 0x558fbd856afa 0x558fbd8c8d00 0x558fbd856afa 0x558fbd8c4915 0x558fbd8c39ee 0x558fbd856bda 0x558fbd8c4915 0x558fbd856afa 0x558fbd8c4915 0x558fbd8c39ee 0x558fbd856bda 0x558fbd8c4915 0x558fbd8c39ee 0x558fbd85748c 0x558fbd857698 0x558fbd8c5fe4 0x558fbd8c39ee 0x558fbd856bda 0x558fbd8c4915 0x558fbd856afa 0x558fbd8c4915 0x558fbd8c39ee 0x558fbd856bda 0x558fbd8c4915 0x558fbd8c39ee\n",
            "  0% 0/268 [00:00<?, ?ba/s]/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1093: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  return (input_length - kernel_size) // stride + 1\n",
            "100% 268/268 [20:08<00:00,  4.51s/ba]\n",
            "WER: 7.53%\n",
            "CPU times: user 11 s, sys: 1.63 s, total: 12.6 s\n",
            "Wall time: 23min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission\n",
        "\n",
        "Creating the submission file submissions/luganda-asr.csv\n",
        "using the ASR model \"indonesian-nlp/wav2vec2-luganda\" on the test set\n",
        "provided by Zindi.\n",
        "It takes around 40 minutes"
      ],
      "metadata": {
        "id": "-X1KGoJrWEiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "!mkdir -p submissions\n",
        "# For testing purpose, create submission file for 1% of test dataset\n",
        "#!python run_submission.py -o submissions/luganda-asr.csv -m indonesian-nlp/wav2vec2-luganda --data_dir /content/data/zindi -k 5gram.bin --test_pct 1\n",
        "\n",
        "# create submission file for 100% of test dataset\n",
        "!python run_submission.py -o submissions/luganda-asr.csv -m indonesian-nlp/wav2vec2-luganda --data_dir /content/data/zindi -k 5gram.bin\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xtbb0l2G6Q4k",
        "outputId": "73a6c22f-dda9-4e67-a474-033661aa3ebe"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
            "No known unigrams provided, decoding results might be a lot worse.\n",
            "Using custom data configuration lg-e6ac6d8c877e86bb\n",
            "Reusing dataset zindi (/root/.cache/huggingface/datasets/zindi/lg-e6ac6d8c877e86bb/1.0.0/48535cc6e254ea4fe8bd529ebd18452c88df0776030e5c69a33ea03b6bcf7436)\n",
            "100% 71/71 [00:00<00:00, 104.72ex/s]\n",
            "  0% 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1093: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  return (input_length - kernel_size) // stride + 1\n",
            "100% 5/5 [00:21<00:00,  4.25s/it]\n",
            "\n",
            "The prediction result has been saved to submissions/luganda-asr.csv\n",
            "CPU times: user 320 ms, sys: 80.5 ms, total: 400 ms\n",
            "Wall time: 43.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nFnbt_56-LJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "btD_5yRx-SJl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}